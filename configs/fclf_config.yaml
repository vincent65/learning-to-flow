model:
  embedding_dim: 512
  num_attributes: 5
  hidden_dim: 256

training:
  num_epochs: 50
  batch_size: 512  # Increased from 128 to fully utilize L4 GPU (23GB memory)
  learning_rate: 0.0001  # 1e-4 in decimal notation for YAML compatibility
  alpha: 0.05  # Flow step size (reduced from 0.1 to encourage smaller movements)

loss:
  temperature: 0.07
  lambda_contrastive: 0.2  # Reduce contrastive pull to prevent mode collapse
  lambda_curl: 0.05  # Increased for smoother flows
  lambda_div: 0.05   # Increased for smoother flows
  lambda_identity: 0.8  # Strong identity preservation to maintain diversity
  # Was 0.2 (too weak, allowed collapse), now 0.8 (strong diversity preservation)

inference:
  num_flow_steps: 10
  step_size: 0.1
