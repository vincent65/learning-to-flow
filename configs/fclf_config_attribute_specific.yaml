model:
  embedding_dim: 512
  num_attributes: 5
  hidden_dim: 256
  projection_radius: 1.0
  architecture: "attribute_specific"  # NEW: Separate head per attribute

training:
  num_epochs: 100
  batch_size: 512
  learning_rate: 0.0001
  alpha: 0.15

loss:
  # Per-attribute contrastive loss (much softer)
  temperature: 0.2
  lambda_contrastive: 0.5

  # Manifold preservation
  lambda_identity: 0.1          # Weak constraint to stay near manifold
  lambda_curl: 0.01             # Smooth flows
  lambda_div: 0.01              # Preserve volume

  # NEW: Orthogonality loss to make attribute flows independent
  lambda_orthogonal: 0.1

inference:
  num_flow_steps: 10
  step_size: 0.1
