# Softer clustering version - use if full training shows <60% uniqueness
#
# Changes from default:
# 1. Higher temperature (0.3 -> even softer clustering)
# 2. Lower contrastive weight (0.3 -> weaker pull to centroids)
# 3. Higher identity weight (0.3 -> stronger manifold preservation)

model:
  embedding_dim: 512
  num_attributes: 5
  hidden_dim: 256
  projection_radius: 1.0

data:
  celeba_root: "data/celeba"
  embedding_dir: "data/embeddings"

training:
  num_epochs: 100
  batch_size: 512
  learning_rate: 0.0001
  alpha: 0.12
  flow_steps: 10

loss:
  # SOFTER CLUSTERING - reduces mode collapse
  temperature: 0.3  # Increased from 0.2
  lambda_contrastive: 0.3  # Reduced from 0.5

  # Attribute independence
  lambda_orthogonal: 0.1

  # STRONGER MANIFOLD PRESERVATION - keeps embeddings spread out
  lambda_identity: 0.3  # Increased from 0.2

  # Trajectory smoothness
  lambda_smoothness: 0.1

  # Optional regularization
  lambda_curl: 0.0
  lambda_div: 0.0

inference:
  num_flow_steps: 10
  step_size: 0.1
